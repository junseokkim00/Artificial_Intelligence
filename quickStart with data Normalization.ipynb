{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuickStart of using Pytorch W/ Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "       transforms.ToTensor()\n",
    "       # normalize here \n",
    "    ]),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy way for normalization: use one whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=len(training_data), num_workers=1)\n",
    "data = next(iter(train_dataloader))\n",
    "data[0].mean(), data[0].std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harder way: divide into smaller batch_size and make many dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=1000, num_workers=1)\n",
    "num_of_pixels = len(training_data) * 28 * 28\n",
    "\n",
    "total_sum = 0\n",
    "count = 0\n",
    "for batch in train_dataloader:\n",
    "    total_sum += batch[0].sum()\n",
    "mean = total_sum / num_of_pixels\n",
    "print(count)\n",
    "\n",
    "sum_of_squared_error = 0\n",
    "for batch in train_dataloader:\n",
    "    sum_of_squared_error += ((batch[0]-mean).pow(2)).sum()\n",
    "std = torch.sqrt(sum_of_squared_error/ num_of_pixels)\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fa76a0a8f10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "plt.hist(data[0].flatten())\n",
    "plt.axvline(data[0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_set_normal = datasets.FashionMNIST(\n",
    "    root='data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        ,transforms.Normalize(mean, std)\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_data_set_normal = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After normalization of the dataset, the mean is also close to 0, and the standard deviation is set to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(training_data_set_normal, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data_set_normal, batch_size=batch_size)\n",
    "\n",
    "for X,y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could learn that \n",
    "+ number of data used for training the model: 64\n",
    "+ channel: 1\n",
    "+ height: 28\n",
    "+ width: 28"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to optimize the model parameters via training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() # we are solving classification problems\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # use basic stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "loss: 2.284086  [   64/60000]\n",
      "loss: 2.212807  [ 6464/60000]\n",
      "loss: 2.120860  [12864/60000]\n",
      "loss: 2.080155  [19264/60000]\n",
      "loss: 1.938097  [25664/60000]\n",
      "loss: 1.864579  [32064/60000]\n",
      "loss: 1.751099  [38464/60000]\n",
      "loss: 1.629717  [44864/60000]\n",
      "loss: 1.583086  [51264/60000]\n",
      "loss: 1.409731  [57664/60000]\n",
      "Epoch 2\n",
      "\n",
      "loss: 1.460557  [   64/60000]\n",
      "loss: 1.422898  [ 6464/60000]\n",
      "loss: 1.176668  [12864/60000]\n",
      "loss: 1.306518  [19264/60000]\n",
      "loss: 1.071939  [25664/60000]\n",
      "loss: 1.121046  [32064/60000]\n",
      "loss: 1.078897  [38464/60000]\n",
      "loss: 1.031362  [44864/60000]\n",
      "loss: 1.079095  [51264/60000]\n",
      "loss: 0.983667  [57664/60000]\n",
      "Epoch 3\n",
      "\n",
      "loss: 0.977201  [   64/60000]\n",
      "loss: 1.040050  [ 6464/60000]\n",
      "loss: 0.786051  [12864/60000]\n",
      "loss: 1.011622  [19264/60000]\n",
      "loss: 0.839215  [25664/60000]\n",
      "loss: 0.880766  [32064/60000]\n",
      "loss: 0.878852  [38464/60000]\n",
      "loss: 0.844518  [44864/60000]\n",
      "loss: 0.899140  [51264/60000]\n",
      "loss: 0.835185  [57664/60000]\n",
      "Epoch 4\n",
      "\n",
      "loss: 0.766321  [   64/60000]\n",
      "loss: 0.871214  [ 6464/60000]\n",
      "loss: 0.626794  [12864/60000]\n",
      "loss: 0.874136  [19264/60000]\n",
      "loss: 0.764576  [25664/60000]\n",
      "loss: 0.766061  [32064/60000]\n",
      "loss: 0.782724  [38464/60000]\n",
      "loss: 0.758824  [44864/60000]\n",
      "loss: 0.807519  [51264/60000]\n",
      "loss: 0.757778  [57664/60000]\n",
      "Epoch 5\n",
      "\n",
      "loss: 0.646625  [   64/60000]\n",
      "loss: 0.771333  [ 6464/60000]\n",
      "loss: 0.538820  [12864/60000]\n",
      "loss: 0.797274  [19264/60000]\n",
      "loss: 0.722380  [25664/60000]\n",
      "loss: 0.698191  [32064/60000]\n",
      "loss: 0.728395  [38464/60000]\n",
      "loss: 0.715168  [44864/60000]\n",
      "loss: 0.755801  [51264/60000]\n",
      "loss: 0.708328  [57664/60000]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    # test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By training the vanilla model from the [link](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html), we got $1.1$ of AVG loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.356318 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, data normalization is effect only if the testing set is also normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model_data_normalization.pth\")\n",
    "print(\"Saved PyTorch Model State to model_data_normalization.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
