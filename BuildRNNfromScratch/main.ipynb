{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN from Scratch(using Numpy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN states for 'Recurrent Neural Network'. As you push the input, it is going to pass the Memory cell(Green box), and conveys the output of the Memory cell which is called 'hidden state' to the output layer but also pass the hidden_state back to its Memory cell again\n",
    "\n",
    "![RNN](https://wikidocs.net/images/page/22886/rnn_image2_ver3.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the parameters, we have the following:\n",
    "* timesteps: the length of the input sentence\n",
    "* input_size: the dim of the word vector\n",
    "* hidden_size: the dim of the hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 10 # length of the sentence\n",
    "input_size = 4 # dim of word vector\n",
    "hidden_size = 8 # dim of hidden_state\n",
    "\n",
    "inputs = np.random.random((timesteps, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state_t = np.zeros((hidden_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(hidden_state_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of how it actually works would be the following:\n",
    "\n",
    "<img align=\"center\" src=\"https://wikidocs.net/images/page/22886/rnn_image4_ver2.PNG\"/>\n",
    "\n",
    "$h_t = tanh(W_xx_t+W_hh_{t-1}+b)$\n",
    "\n",
    "$y_t = f(W_yh_t + b)$   ($f$ stands for activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wx = np.random.random((hidden_size, input_size))\n",
    "\n",
    "Wh = np.random.random((hidden_size, hidden_size))\n",
    "\n",
    "b = np.random.random((hidden_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "total_hidden_states= []\n",
    "\n",
    "for input_t in inputs:\n",
    "    output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh, hidden_state_t) + b)\n",
    "    total_hidden_states.append(output_t)\n",
    "    hidden_state_t = output_t\n",
    "    # Originally the f(Wy*ht + b) should be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
