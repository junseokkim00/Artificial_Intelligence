{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvXwwn5b6oM9"
      },
      "source": [
        "# 2. Linear Regression\n",
        "## 2-1 Linear Regression\n",
        "1. Data Definition\n",
        "2. Hypothesis\n",
        "3. Compute Loss\n",
        "4. Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkcBedAH64nL"
      },
      "source": [
        "### 1. Data Definition\n",
        "$X_{train}$: feature(입력, 특징들)\n",
        "$Y_{train}$: label(결과값)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L7giDEL7IuK"
      },
      "source": [
        "### 2. Hypothesis\n",
        "\n",
        "$x$를 이용하여 $y$에 대한 식을 구성하는 것\n",
        "* input을 이용하여 output을 구하는 전체적인 구조를 의미\n",
        "\n",
        "*example*\n",
        "\n",
        "$y=Wx+b$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3MqQdgb7fpj"
      },
      "source": [
        "### 3. Loss\n",
        "\n",
        "cost function = loss function = objective function\n",
        "\n",
        "example: MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2klYkXCl6lSh"
      },
      "source": [
        "### 4. Gradient Descent\n",
        "\n",
        "computing the gradient of each variable and subtracting from the weight could modify the weight to have a better output. This leads to compute a better model than before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRrgDyyw8akV"
      },
      "source": [
        "### 5. Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UQcb73kS7fA7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5IQPn2o8huZ",
        "outputId": "3bdea968-081e-4098-92d0-d1e60cdefd11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1064d3e30>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ahD6KUR38lWb"
      },
      "outputs": [],
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhOGN0Y68vaB",
        "outputId": "f3f5d1ef-d082-4658-af42-2d677ec4a601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "W = torch.zeros(1, requires_grad=True) #requires_grad: autograd를 사용할건지\n",
        "print(W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS3SAGrD9E_X",
        "outputId": "b8d6989d-9fa3-4954-b18e-ddc0450a113a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "b = torch.zeros(1, requires_grad=True)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEtac7pw9JmM",
        "outputId": "76703a72-c2c8-4d75-bdec-ac7be71c30c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "hypothesis = x_train * W + b\n",
        "print(hypothesis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1lXcbPd9PiT",
        "outputId": "3542aa20-df1e-4a30-dfe1-d7fefbf2f48b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "cost = torch.mean((hypothesis - y_train)**2)\n",
        "print(cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "q-IpyssJ9XTB"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD([W, b], lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-MzAvb1e9dYh"
      },
      "outputs": [],
      "source": [
        "optimizer.zero_grad() #gradient 0으로 초기화\n",
        "\n",
        "cost.backward() #cost function의 gradient 계산\n",
        "\n",
        "optimizer.step() # update parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33qAxZPT91Mc",
        "outputId": "8d71a1a2-ddca-4800-b48c-20c3e9091dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 W: 0.187, b: 0.080 Cost: 18.666666\n",
            "Epoch  100/2000 W: 1.746, b: 0.578 Cost: 0.048171\n",
            "Epoch  200/2000 W: 1.800, b: 0.454 Cost: 0.029767\n",
            "Epoch  300/2000 W: 1.843, b: 0.357 Cost: 0.018394\n",
            "Epoch  400/2000 W: 1.876, b: 0.281 Cost: 0.011366\n",
            "Epoch  500/2000 W: 1.903, b: 0.221 Cost: 0.007024\n",
            "Epoch  600/2000 W: 1.924, b: 0.174 Cost: 0.004340\n",
            "Epoch  700/2000 W: 1.940, b: 0.136 Cost: 0.002682\n",
            "Epoch  800/2000 W: 1.953, b: 0.107 Cost: 0.001657\n",
            "Epoch  900/2000 W: 1.963, b: 0.084 Cost: 0.001024\n",
            "Epoch 1000/2000 W: 1.971, b: 0.066 Cost: 0.000633\n",
            "Epoch 1100/2000 W: 1.977, b: 0.052 Cost: 0.000391\n",
            "Epoch 1200/2000 W: 1.982, b: 0.041 Cost: 0.000242\n",
            "Epoch 1300/2000 W: 1.986, b: 0.032 Cost: 0.000149\n",
            "Epoch 1400/2000 W: 1.989, b: 0.025 Cost: 0.000092\n",
            "Epoch 1500/2000 W: 1.991, b: 0.020 Cost: 0.000057\n",
            "Epoch 1600/2000 W: 1.993, b: 0.016 Cost: 0.000035\n",
            "Epoch 1700/2000 W: 1.995, b: 0.012 Cost: 0.000022\n",
            "Epoch 1800/2000 W: 1.996, b: 0.010 Cost: 0.000013\n",
            "Epoch 1900/2000 W: 1.997, b: 0.008 Cost: 0.000008\n",
            "Epoch 2000/2000 W: 1.997, b: 0.006 Cost: 0.000005\n"
          ]
        }
      ],
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "W = torch.zeros(1, requires_grad=True) #requires_grad: autograd를 사용할건지\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "num_epochs = 2000\n",
        "for epoch in range(num_epochs+1):\n",
        "  hypothesis = x_train * W + b\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, num_epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sen1ewGi-p2H"
      },
      "source": [
        "> optimizer.zero_grad 의 필요성: pytorch accumulates the value of gradients, so it is essential to initialize the value of gradient in to 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfUXvFFOIce_"
      },
      "source": [
        "## 2-2 Autograd\n",
        "\n",
        "* Try to understand the following principles(requires_grad, backward etc)\n",
        "* Autograd helps user to run gradient descent easilyby computing the gradient of the given function automatically "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a-eY-o9IzdT",
        "outputId": "0a15132f-7f33-4278-aa9a-a5c8995a3a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2., requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "w = torch.tensor(2.0, requires_grad= True)\n",
        "print(w)\n",
        "\n",
        "y = w**2\n",
        "z = 2*y + 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpqfhAhlJQ7v",
        "outputId": "02f3c8ad-da9c-46bb-e4f1-ee546bdf1cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2., requires_grad=True) tensor(4., grad_fn=<PowBackward0>) tensor(13., grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(w, y ,z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ktKPt0fSJSmw"
      },
      "outputs": [],
      "source": [
        "z.backward() #parameter에 대해서 기울기를 계산한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwKA0Q1fJbhA",
        "outputId": "e8e58447-5d0e-40a7-99b2-e780927472ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.)\n"
          ]
        }
      ],
      "source": [
        "print(w.grad) # w가 속한 수식을 w로 미분한 값이 저장되어 있음 (backward를 통해 얻은 미분값)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7V08f04JgOc"
      },
      "source": [
        "## 2-3 Multivariable Linear regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yAj2YoTSK6uT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6Gc1TvlK67U",
        "outputId": "3d5ab82d-93ad-45f8-b4f1-92b40f29e6cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1064d3e30>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hny5OexLEFd"
      },
      "source": [
        "$H(x) = w_1x_1 + w_2x_2 + w_3x_3 + b$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9ySsnszlLMLv"
      },
      "outputs": [],
      "source": [
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wwlThGTJLetu"
      },
      "outputs": [],
      "source": [
        "w1 = torch.zeros(1, requires_grad= True)\n",
        "w2 = torch.zeros(1, requires_grad= True)\n",
        "w3 = torch.zeros(1, requires_grad= True)\n",
        "b = torch.zeros(1, requires_grad= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQi3_s4mLrph",
        "outputId": "ffbdf6db-a268-40ae-c4fc-e5573254e545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
            "Epoch  100/2000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost: 1.563628\n",
            "Epoch  200/2000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost: 1.497595\n",
            "Epoch  300/2000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost: 1.435044\n",
            "Epoch  400/2000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost: 1.375726\n",
            "Epoch  500/2000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost: 1.319507\n",
            "Epoch  600/2000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost: 1.266222\n",
            "Epoch  700/2000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost: 1.215703\n",
            "Epoch  800/2000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost: 1.167810\n",
            "Epoch  900/2000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost: 1.122429\n",
            "Epoch 1000/2000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079390\n",
            "Epoch 1100/2000 w1: 0.722 w2: 0.608 w3: 0.680 b: 0.009 Cost: 1.038574\n",
            "Epoch 1200/2000 w1: 0.727 w2: 0.603 w3: 0.681 b: 0.010 Cost: 0.999884\n",
            "Epoch 1300/2000 w1: 0.731 w2: 0.599 w3: 0.681 b: 0.010 Cost: 0.963217\n",
            "Epoch 1400/2000 w1: 0.735 w2: 0.595 w3: 0.681 b: 0.010 Cost: 0.928427\n",
            "Epoch 1500/2000 w1: 0.739 w2: 0.591 w3: 0.681 b: 0.010 Cost: 0.895448\n",
            "Epoch 1600/2000 w1: 0.743 w2: 0.586 w3: 0.682 b: 0.010 Cost: 0.864169\n",
            "Epoch 1700/2000 w1: 0.746 w2: 0.583 w3: 0.682 b: 0.010 Cost: 0.834509\n",
            "Epoch 1800/2000 w1: 0.750 w2: 0.579 w3: 0.682 b: 0.010 Cost: 0.806380\n",
            "Epoch 1900/2000 w1: 0.754 w2: 0.575 w3: 0.682 b: 0.010 Cost: 0.779696\n",
            "Epoch 2000/2000 w1: 0.757 w2: 0.571 w3: 0.682 b: 0.011 Cost: 0.754379\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
        "num_epochs = 2000\n",
        "for epoch in range(num_epochs+1):\n",
        "  hypothesis = x1_train*w1+x2_train*w2+x3_train*w3+b\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, num_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbmqOa8JMPCL"
      },
      "source": [
        "지금까지는 hypothesis를 적을 때 직접 하나씩 곱셈으로 표시하여 명시했다. 이제부터는 행렬 연산을 이용하여 훨씬 더 편리하게 적을 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "j-y10t6eNt4r"
      },
      "outputs": [],
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  80], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcA-kusaNw2s",
        "outputId": "22190316-9cdf-4e90-e2d8-b2741d6d3caf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 1])\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dNDfWi5DN0WE"
      },
      "outputs": [],
      "source": [
        "W = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "RBYAzmUAN4NJ"
      },
      "outputs": [],
      "source": [
        "hypothesis = x_train @ W + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxbR9VnEN-P7",
        "outputId": "418fec67-674e-419e-bd9e-5e125baeb9c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch    1/20 hypothesis: tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]) Cost: 9537.694336\n",
            "Epoch    2/20 hypothesis: tensor([104.5421, 125.6208, 119.2478, 134.7861,  95.8280]) Cost: 3069.590332\n",
            "Epoch    3/20 hypothesis: tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]) Cost: 990.670715\n",
            "Epoch    4/20 hypothesis: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]) Cost: 322.481903\n",
            "Epoch    5/20 hypothesis: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]) Cost: 107.717003\n",
            "Epoch    6/20 hypothesis: tensor([148.9423, 178.9731, 169.8976, 192.0301, 136.5279]) Cost: 38.687401\n",
            "Epoch    7/20 hypothesis: tensor([151.1574, 181.6347, 172.4254, 194.8856, 138.5585]) Cost: 16.499033\n",
            "Epoch    8/20 hypothesis: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]) Cost: 9.365660\n",
            "Epoch    9/20 hypothesis: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]) Cost: 7.071114\n",
            "Epoch   10/20 hypothesis: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]) Cost: 6.331867\n",
            "Epoch   11/20 hypothesis: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]) Cost: 6.092538\n",
            "Epoch   12/20 hypothesis: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0614]) Cost: 6.013823\n",
            "Epoch   13/20 hypothesis: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]) Cost: 5.986778\n",
            "Epoch   14/20 hypothesis: tensor([154.0017, 185.0517, 175.6785, 198.5501, 141.1671]) Cost: 5.976319\n",
            "Epoch   15/20 hypothesis: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]) Cost: 5.971208\n",
            "Epoch   16/20 hypothesis: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]) Cost: 5.967835\n",
            "Epoch   17/20 hypothesis: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]) Cost: 5.964969\n",
            "Epoch   18/20 hypothesis: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]) Cost: 5.962291\n",
            "Epoch   19/20 hypothesis: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]) Cost: 5.959676\n",
            "Epoch   20/20 hypothesis: tensor([154.0536, 185.1134, 175.7451, 198.6146, 141.2158]) Cost: 5.957105\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.SGD([W, b], lr=1e-5)\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs+1):\n",
        "  hypothesis = x_train @ W + b\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "        epoch, num_epochs, hypothesis.squeeze().detach(), cost.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jviUS2bLOYs9"
      },
      "source": [
        "## 2-4 Linear Regression using `nn.Module`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJEwhbJ2PhrM",
        "outputId": "23d30591-2ac1-44e1-fd27-ca8623c92901"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1064d3e30>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tolkDV9mPzYw"
      },
      "outputs": [],
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2tCY97MP3Dq",
        "outputId": "bf2bb3a7-0d4c-4559-d161-26e79138db1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "OhO-dM0aP7dc"
      },
      "outputs": [],
      "source": [
        "model = nn.Linear(1, 1) #input_dim:1, output_dim:1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "675c1EOVQVwi",
        "outputId": "3c312db8-baac-46bd-d2b5-96fb4e8af6c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.7645]], requires_grad=True), Parameter containing:\n",
            "tensor([0.8300], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "print(list(model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4HmU7VWQfIL",
        "outputId": "938afb7e-60a1-422e-bb1d-dffdddffd8af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 Cost: 3.710179\n",
            "Epoch  100/2000 Cost: 0.117398\n",
            "Epoch  200/2000 Cost: 0.072545\n",
            "Epoch  300/2000 Cost: 0.044828\n",
            "Epoch  400/2000 Cost: 0.027701\n",
            "Epoch  500/2000 Cost: 0.017118\n",
            "Epoch  600/2000 Cost: 0.010578\n",
            "Epoch  700/2000 Cost: 0.006536\n",
            "Epoch  800/2000 Cost: 0.004039\n",
            "Epoch  900/2000 Cost: 0.002496\n",
            "Epoch 1000/2000 Cost: 0.001542\n",
            "Epoch 1100/2000 Cost: 0.000953\n",
            "Epoch 1200/2000 Cost: 0.000589\n",
            "Epoch 1300/2000 Cost: 0.000364\n",
            "Epoch 1400/2000 Cost: 0.000225\n",
            "Epoch 1500/2000 Cost: 0.000139\n",
            "Epoch 1600/2000 Cost: 0.000086\n",
            "Epoch 1700/2000 Cost: 0.000053\n",
            "Epoch 1800/2000 Cost: 0.000033\n",
            "Epoch 1900/2000 Cost: 0.000020\n",
            "Epoch 2000/2000 Cost: 0.000013\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr= 0.01)\n",
        "num_epochs = 2000\n",
        "for epoch in range(num_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, num_epochs, cost.item()\n",
        "      ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AZkk-wfRSnT",
        "outputId": "b5d95b18-8f24-4133-a3f7-f12796a05e36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[7.9929]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "new_var = torch.FloatTensor([[4.0]])\n",
        "\n",
        "pred_y = model(new_var)\n",
        "\n",
        "print(pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tOfeQn1Rh2q",
        "outputId": "7eb4dbd0-9459-45bf-9e49-16b7448af0b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9959]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0093], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "print(list(model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHfudr3zRqxr"
      },
      "source": [
        "다중 선형회귀도 `nn.module`을 통해 구현할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKd8baNFR5tx",
        "outputId": "815de7e8-975c-448b-fdaf-ec386ebd3b08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1064d3e30>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBzq4TaxSA4d",
        "outputId": "73ce674d-2a0b-476a-bb1b-56df7762837b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 1])\n"
          ]
        }
      ],
      "source": [
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxJ4JvUdSF9A",
        "outputId": "04fe9a7c-d949-4300-f70e-74b99c295dfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.4414,  0.4792, -0.1353]], requires_grad=True), Parameter containing:\n",
            "tensor([0.5304], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "model = nn.Linear(3, 1)\n",
        "print(list(model.parameters())) # 3 W, 1 b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XqsEfDOSNnG",
        "outputId": "8657b860-2f44-4c8d-c7ec-468b067d2a26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 Cost: 10995.318359\n",
            "Epoch  100/2000 Cost: 2.533235\n",
            "Epoch  200/2000 Cost: 2.409113\n",
            "Epoch  300/2000 Cost: 2.291542\n",
            "Epoch  400/2000 Cost: 2.180169\n",
            "Epoch  500/2000 Cost: 2.074663\n",
            "Epoch  600/2000 Cost: 1.974701\n",
            "Epoch  700/2000 Cost: 1.880022\n",
            "Epoch  800/2000 Cost: 1.790340\n",
            "Epoch  900/2000 Cost: 1.705370\n",
            "Epoch 1000/2000 Cost: 1.624879\n",
            "Epoch 1100/2000 Cost: 1.548624\n",
            "Epoch 1200/2000 Cost: 1.476396\n",
            "Epoch 1300/2000 Cost: 1.407958\n",
            "Epoch 1400/2000 Cost: 1.343144\n",
            "Epoch 1500/2000 Cost: 1.281701\n",
            "Epoch 1600/2000 Cost: 1.223541\n",
            "Epoch 1700/2000 Cost: 1.168417\n",
            "Epoch 1800/2000 Cost: 1.116197\n",
            "Epoch 1900/2000 Cost: 1.066716\n",
            "Epoch 2000/2000 Cost: 1.019860\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "num_epochs = 2000\n",
        "for epoch in range(num_epochs+1):\n",
        "  pred = model(x_train)\n",
        "  cost = F.mse_loss(pred, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, num_epochs, cost.item()\n",
        "      ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry-urTrnTDN5",
        "outputId": "640b364c-3d78-4e3f-9ada-94639e5da487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[153.0205]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "new_var = torch.FloatTensor([[73, 80, 75]])\n",
        "pred_y = model(new_var)\n",
        "print(pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40-ugznMTUOv",
        "outputId": "a573562f-8d43-4a8e-ffea-d87c5049c77f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.9541, 0.7449, 0.3099]], requires_grad=True), Parameter containing:\n",
            "tensor([0.5356], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "print(list(model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_la8b5bTY8O"
      },
      "source": [
        "## 2-5 Implement Pytorch model using class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "DD4MYIREULce"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "#using nn.module\n",
        "model = nn.Linear(1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "zCHrFZupUVky"
      },
      "outputs": [],
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(1, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "CumM_xAXUoGR"
      },
      "outputs": [],
      "source": [
        "model_lrm = LinearRegressionModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "gkZ7TXw4UqOo"
      },
      "outputs": [],
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "u5xdDqjRVA1p"
      },
      "outputs": [],
      "source": [
        "model_mlrm = MultivariateLinearRegressionModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNlT6bXZVEYb"
      },
      "source": [
        "## 2-6 Mini Batch and Data Load\n",
        "\n",
        "* Learn how to load data\n",
        "* Minibatch Gradient Descent\n",
        "\n",
        "Minibatch란 학습시킬 데이터를 나누어서 학습을 시키는데 이때 나눈 한 뭉텅이의 단위를 minibatch라고 한다.\n",
        "\n",
        "minibatch로 전체 데이터에 대한 학습이 1회 끝나면 1 에포크가 끝났다고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2fbViLPW3jc"
      },
      "source": [
        "### Batch size, Iteration, and epoch\n",
        "\n",
        "* Batch size: 한번 학습시킬 때 사용할 데이터의 개수 -> mini batch에 size\n",
        "* epoch: 전체 데이터에 대한 학습을 1번 끝낸 횟수\n",
        "* Iteration: 1 epoch을 끝내기 위해 batch의 개수(1epoch을 위한 학습 횟수)\n",
        "\n",
        "![batch, iteration, and epoch](https://wikidocs.net/images/page/36033/batchandepochiteration.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd6YDVjGZc5C"
      },
      "source": [
        "### Data Load\n",
        "\n",
        "Pytorch offers Dataset and DataLoader, which could conduct mini batch training, shuffle, parellel operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "uK7TMXfyZbSt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "RaVQ81FjZz8j"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "IqWoqvnVZ9rX"
      },
      "outputs": [],
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  90], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "xKDiEV1aaABs"
      },
      "outputs": [],
      "source": [
        "dataset = TensorDataset(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "FuU5_CzlaD52"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset,batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "xPHhRibwaNZD"
      },
      "outputs": [],
      "source": [
        "model=nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KVxqprjaVgu",
        "outputId": "19951340-62e0-4ce5-afe1-90e4e2b0aac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch_idx: 0, samples: [tensor([[73., 66., 70.],\n",
            "        [89., 91., 90.]]), tensor([[142.],\n",
            "        [180.]])]\n",
            "Epoch    0/20 Batch 1/3 Cost: 9767.699219\n",
            "batch_idx: 1, samples: [tensor([[ 96.,  98., 100.],\n",
            "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
            "        [185.]])]\n",
            "Epoch    0/20 Batch 2/3 Cost: 5038.088379\n",
            "batch_idx: 2, samples: [tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    0/20 Batch 3/3 Cost: 723.783325\n",
            "batch_idx: 0, samples: [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
            "        [142.]])]\n",
            "Epoch    1/20 Batch 1/3 Cost: 361.084839\n",
            "batch_idx: 1, samples: [tensor([[93., 88., 93.],\n",
            "        [73., 80., 75.]]), tensor([[185.],\n",
            "        [152.]])]\n",
            "Epoch    1/20 Batch 2/3 Cost: 125.787079\n",
            "batch_idx: 2, samples: [tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
            "Epoch    1/20 Batch 3/3 Cost: 34.142281\n",
            "batch_idx: 0, samples: [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
            "        [142.]])]\n",
            "Epoch    2/20 Batch 1/3 Cost: 11.149569\n",
            "batch_idx: 1, samples: [tensor([[93., 88., 93.],\n",
            "        [73., 80., 75.]]), tensor([[185.],\n",
            "        [152.]])]\n",
            "Epoch    2/20 Batch 2/3 Cost: 5.840169\n",
            "batch_idx: 2, samples: [tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
            "Epoch    2/20 Batch 3/3 Cost: 0.167853\n",
            "batch_idx: 0, samples: [tensor([[73., 80., 75.],\n",
            "        [73., 66., 70.]]), tensor([[152.],\n",
            "        [142.]])]\n",
            "Epoch    3/20 Batch 1/3 Cost: 1.557407\n",
            "batch_idx: 1, samples: [tensor([[ 89.,  91.,  90.],\n",
            "        [ 96.,  98., 100.]]), tensor([[180.],\n",
            "        [196.]])]\n",
            "Epoch    3/20 Batch 2/3 Cost: 0.118916\n",
            "batch_idx: 2, samples: [tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
            "Epoch    3/20 Batch 3/3 Cost: 0.887999\n",
            "batch_idx: 0, samples: [tensor([[ 73.,  80.,  75.],\n",
            "        [ 96.,  98., 100.]]), tensor([[152.],\n",
            "        [196.]])]\n",
            "Epoch    4/20 Batch 1/3 Cost: 0.380325\n",
            "batch_idx: 1, samples: [tensor([[93., 88., 93.],\n",
            "        [89., 91., 90.]]), tensor([[185.],\n",
            "        [180.]])]\n",
            "Epoch    4/20 Batch 2/3 Cost: 0.272152\n",
            "batch_idx: 2, samples: [tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
            "Epoch    4/20 Batch 3/3 Cost: 0.616327\n",
            "batch_idx: 0, samples: [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
            "        [142.]])]\n",
            "Epoch    5/20 Batch 1/3 Cost: 0.621912\n",
            "batch_idx: 1, samples: [tensor([[73., 80., 75.],\n",
            "        [93., 88., 93.]]), tensor([[152.],\n",
            "        [185.]])]\n",
            "Epoch    5/20 Batch 2/3 Cost: 0.169239\n",
            "batch_idx: 2, samples: [tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
            "Epoch    5/20 Batch 3/3 Cost: 0.689435\n",
            "batch_idx: 0, samples: [tensor([[73., 66., 70.],\n",
            "        [73., 80., 75.]]), tensor([[142.],\n",
            "        [152.]])]\n",
            "Epoch    6/20 Batch 1/3 Cost: 0.543665\n",
            "batch_idx: 1, samples: [tensor([[93., 88., 93.],\n",
            "        [89., 91., 90.]]), tensor([[185.],\n",
            "        [180.]])]\n",
            "Epoch    6/20 Batch 2/3 Cost: 0.305701\n",
            "batch_idx: 2, samples: [tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
            "Epoch    6/20 Batch 3/3 Cost: 0.597026\n",
            "batch_idx: 0, samples: [tensor([[ 96.,  98., 100.],\n",
            "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
            "        [180.]])]\n",
            "Epoch    7/20 Batch 1/3 Cost: 0.075517\n",
            "batch_idx: 1, samples: [tensor([[93., 88., 93.],\n",
            "        [73., 66., 70.]]), tensor([[185.],\n",
            "        [142.]])]\n",
            "Epoch    7/20 Batch 2/3 Cost: 1.096707\n",
            "batch_idx: 2, samples: [tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    7/20 Batch 3/3 Cost: 0.286392\n",
            "batch_idx: 0, samples: [tensor([[93., 88., 93.],\n",
            "        [73., 66., 70.]]), tensor([[185.],\n",
            "        [142.]])]\n",
            "Epoch    8/20 Batch 1/3 Cost: 0.221741\n",
            "batch_idx: 1, samples: [tensor([[ 89.,  91.,  90.],\n",
            "        [ 96.,  98., 100.]]), tensor([[180.],\n",
            "        [196.]])]\n",
            "Epoch    8/20 Batch 2/3 Cost: 1.042799\n",
            "batch_idx: 2, samples: [tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    8/20 Batch 3/3 Cost: 0.398523\n",
            "batch_idx: 0, samples: [tensor([[ 89.,  91.,  90.],\n",
            "        [ 96.,  98., 100.]]), tensor([[180.],\n",
            "        [196.]])]\n",
            "Epoch    9/20 Batch 1/3 Cost: 0.563436\n",
            "batch_idx: 1, samples: [tensor([[93., 88., 93.],\n",
            "        [73., 66., 70.]]), tensor([[185.],\n",
            "        [142.]])]\n",
            "Epoch    9/20 Batch 2/3 Cost: 0.736300\n",
            "batch_idx: 2, samples: [tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    9/20 Batch 3/3 Cost: 0.181394\n",
            "batch_idx: 0, samples: [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
            "        [152.]])]\n",
            "Epoch   10/20 Batch 1/3 Cost: 0.537398\n",
            "batch_idx: 1, samples: [tensor([[89., 91., 90.],\n",
            "        [93., 88., 93.]]), tensor([[180.],\n",
            "        [185.]])]\n",
            "Epoch   10/20 Batch 2/3 Cost: 0.278889\n",
            "batch_idx: 2, samples: [tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
            "Epoch   10/20 Batch 3/3 Cost: 0.531269\n",
            "batch_idx: 0, samples: [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
            "        [152.]])]\n",
            "Epoch   11/20 Batch 1/3 Cost: 0.554412\n",
            "batch_idx: 1, samples: [tensor([[93., 88., 93.],\n",
            "        [89., 91., 90.]]), tensor([[185.],\n",
            "        [180.]])]\n",
            "Epoch   11/20 Batch 2/3 Cost: 0.280875\n",
            "batch_idx: 2, samples: [tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
            "Epoch   11/20 Batch 3/3 Cost: 0.524528\n",
            "batch_idx: 0, samples: [tensor([[ 73.,  66.,  70.],\n",
            "        [ 96.,  98., 100.]]), tensor([[142.],\n",
            "        [196.]])]\n",
            "Epoch   12/20 Batch 1/3 Cost: 0.655531\n",
            "batch_idx: 1, samples: [tensor([[89., 91., 90.],\n",
            "        [93., 88., 93.]]), tensor([[180.],\n",
            "        [185.]])]\n",
            "Epoch   12/20 Batch 2/3 Cost: 0.292519\n",
            "batch_idx: 2, samples: [tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   12/20 Batch 3/3 Cost: 0.221274\n",
            "batch_idx: 0, samples: [tensor([[ 96.,  98., 100.],\n",
            "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
            "        [185.]])]\n",
            "Epoch   13/20 Batch 1/3 Cost: 0.491727\n",
            "batch_idx: 1, samples: [tensor([[73., 80., 75.],\n",
            "        [89., 91., 90.]]), tensor([[152.],\n",
            "        [180.]])]\n",
            "Epoch   13/20 Batch 2/3 Cost: 0.289904\n",
            "batch_idx: 2, samples: [tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
            "Epoch   13/20 Batch 3/3 Cost: 0.555245\n",
            "batch_idx: 0, samples: [tensor([[ 89.,  91.,  90.],\n",
            "        [ 96.,  98., 100.]]), tensor([[180.],\n",
            "        [196.]])]\n",
            "Epoch   14/20 Batch 1/3 Cost: 0.845915\n",
            "batch_idx: 1, samples: [tensor([[73., 66., 70.],\n",
            "        [73., 80., 75.]]), tensor([[142.],\n",
            "        [152.]])]\n",
            "Epoch   14/20 Batch 2/3 Cost: 0.619964\n",
            "batch_idx: 2, samples: [tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
            "Epoch   14/20 Batch 3/3 Cost: 0.134827\n",
            "batch_idx: 0, samples: [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
            "        [142.]])]\n",
            "Epoch   15/20 Batch 1/3 Cost: 0.654430\n",
            "batch_idx: 1, samples: [tensor([[73., 80., 75.],\n",
            "        [93., 88., 93.]]), tensor([[152.],\n",
            "        [185.]])]\n",
            "Epoch   15/20 Batch 2/3 Cost: 0.147930\n",
            "batch_idx: 2, samples: [tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
            "Epoch   15/20 Batch 3/3 Cost: 0.716944\n",
            "batch_idx: 0, samples: [tensor([[73., 66., 70.],\n",
            "        [93., 88., 93.]]), tensor([[142.],\n",
            "        [185.]])]\n",
            "Epoch   16/20 Batch 1/3 Cost: 0.527808\n",
            "batch_idx: 1, samples: [tensor([[89., 91., 90.],\n",
            "        [73., 80., 75.]]), tensor([[180.],\n",
            "        [152.]])]\n",
            "Epoch   16/20 Batch 2/3 Cost: 0.336056\n",
            "batch_idx: 2, samples: [tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
            "Epoch   16/20 Batch 3/3 Cost: 0.620526\n",
            "batch_idx: 0, samples: [tensor([[73., 80., 75.],\n",
            "        [93., 88., 93.]]), tensor([[152.],\n",
            "        [185.]])]\n",
            "Epoch   17/20 Batch 1/3 Cost: 0.656451\n",
            "batch_idx: 1, samples: [tensor([[89., 91., 90.],\n",
            "        [73., 66., 70.]]), tensor([[180.],\n",
            "        [142.]])]\n",
            "Epoch   17/20 Batch 2/3 Cost: 0.427250\n",
            "batch_idx: 2, samples: [tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
            "Epoch   17/20 Batch 3/3 Cost: 0.526763\n",
            "batch_idx: 0, samples: [tensor([[93., 88., 93.],\n",
            "        [89., 91., 90.]]), tensor([[185.],\n",
            "        [180.]])]\n",
            "Epoch   18/20 Batch 1/3 Cost: 0.378815\n",
            "batch_idx: 1, samples: [tensor([[73., 66., 70.],\n",
            "        [73., 80., 75.]]), tensor([[142.],\n",
            "        [152.]])]\n",
            "Epoch   18/20 Batch 2/3 Cost: 0.629539\n",
            "batch_idx: 2, samples: [tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
            "Epoch   18/20 Batch 3/3 Cost: 0.671286\n",
            "batch_idx: 0, samples: [tensor([[89., 91., 90.],\n",
            "        [73., 80., 75.]]), tensor([[180.],\n",
            "        [152.]])]\n",
            "Epoch   19/20 Batch 1/3 Cost: 0.334297\n",
            "batch_idx: 1, samples: [tensor([[93., 88., 93.],\n",
            "        [73., 66., 70.]]), tensor([[185.],\n",
            "        [142.]])]\n",
            "Epoch   19/20 Batch 2/3 Cost: 0.662022\n",
            "batch_idx: 2, samples: [tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
            "Epoch   19/20 Batch 3/3 Cost: 0.701677\n",
            "batch_idx: 0, samples: [tensor([[ 73.,  80.,  75.],\n",
            "        [ 96.,  98., 100.]]), tensor([[152.],\n",
            "        [196.]])]\n",
            "Epoch   20/20 Batch 1/3 Cost: 0.366610\n",
            "batch_idx: 1, samples: [tensor([[93., 88., 93.],\n",
            "        [89., 91., 90.]]), tensor([[185.],\n",
            "        [180.]])]\n",
            "Epoch   20/20 Batch 2/3 Cost: 0.317309\n",
            "batch_idx: 2, samples: [tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
            "Epoch   20/20 Batch 3/3 Cost: 0.722874\n"
          ]
        }
      ],
      "source": [
        "num_epochs =20\n",
        "for epoch in range(num_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    print(\"batch_idx: {}, samples: {}\".format(batch_idx, samples))\n",
        "    x_train, y_train = samples\n",
        "    pred = model(x_train)\n",
        "    cost = F.mse_loss(pred, y_train)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "      epoch, num_epochs, batch_idx+1, len(dataloader),\n",
        "      cost.item()\n",
        "      ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH0H_lPYa8Qw",
        "outputId": "246e5828-1713-4b77-cf09-0b99e24427de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[151.6379]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "new_var = torch.FloatTensor([[73, 80, 75]])\n",
        "\n",
        "pred_y = model(new_var)\n",
        "print(pred_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba-y0WLIbs1l"
      },
      "source": [
        "## 2-7 Custom Dataset\n",
        "\n",
        "* By inheriting from torch.utils.data.Dataset, you could make your own custom Dataset\n",
        "\n",
        "```python\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    #데이터 셋의 전처리 담당\n",
        "  def __len__(self):\n",
        "    #데이터셋의 길이, 총 sample의 수를 적어줌\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # 데이터셋에서 특정 1개의 sample을 가져온다.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "i8BNc-pZdCKR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "vjWc_9m9dmSE"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data = [[73, 80, 75],\n",
        "                   [93, 88, 93],\n",
        "                   [89, 91, 90],\n",
        "                   [96, 98, 100],\n",
        "                   [73, 66, 70]]\n",
        "    self.y_data = [[152], [185], [180], [196], [142]]\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "  def __getitem__(self, idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "_JpAEXJpefoB"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "mg8xPVpwennE"
      },
      "outputs": [],
      "source": [
        "model = torch.nn.Linear(3, 1)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXfV2OyyevDq",
        "outputId": "159cde9c-6d2b-414c-cdd5-595f7a9dd271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 39138.378906\n",
            "Epoch    0/20 Batch 2/3 Cost: 10714.405273\n",
            "Epoch    0/20 Batch 3/3 Cost: 4158.664551\n",
            "Epoch    1/20 Batch 1/3 Cost: 1113.740479\n",
            "Epoch    1/20 Batch 2/3 Cost: 341.212341\n",
            "Epoch    1/20 Batch 3/3 Cost: 91.544449\n",
            "Epoch    2/20 Batch 1/3 Cost: 41.474979\n",
            "Epoch    2/20 Batch 2/3 Cost: 26.065870\n",
            "Epoch    2/20 Batch 3/3 Cost: 0.137971\n",
            "Epoch    3/20 Batch 1/3 Cost: 12.251788\n",
            "Epoch    3/20 Batch 2/3 Cost: 6.731195\n",
            "Epoch    3/20 Batch 3/3 Cost: 1.802672\n",
            "Epoch    4/20 Batch 1/3 Cost: 1.375394\n",
            "Epoch    4/20 Batch 2/3 Cost: 7.725240\n",
            "Epoch    4/20 Batch 3/3 Cost: 16.293694\n",
            "Epoch    5/20 Batch 1/3 Cost: 9.256533\n",
            "Epoch    5/20 Batch 2/3 Cost: 4.672593\n",
            "Epoch    5/20 Batch 3/3 Cost: 13.019217\n",
            "Epoch    6/20 Batch 1/3 Cost: 3.796662\n",
            "Epoch    6/20 Batch 2/3 Cost: 15.531879\n",
            "Epoch    6/20 Batch 3/3 Cost: 4.352408\n",
            "Epoch    7/20 Batch 1/3 Cost: 5.348221\n",
            "Epoch    7/20 Batch 2/3 Cost: 3.886833\n",
            "Epoch    7/20 Batch 3/3 Cost: 19.480984\n",
            "Epoch    8/20 Batch 1/3 Cost: 4.417746\n",
            "Epoch    8/20 Batch 2/3 Cost: 9.332916\n",
            "Epoch    8/20 Batch 3/3 Cost: 3.950957\n",
            "Epoch    9/20 Batch 1/3 Cost: 6.320132\n",
            "Epoch    9/20 Batch 2/3 Cost: 1.982779\n",
            "Epoch    9/20 Batch 3/3 Cost: 18.569372\n",
            "Epoch   10/20 Batch 1/3 Cost: 4.485127\n",
            "Epoch   10/20 Batch 2/3 Cost: 6.036551\n",
            "Epoch   10/20 Batch 3/3 Cost: 16.500807\n",
            "Epoch   11/20 Batch 1/3 Cost: 7.823772\n",
            "Epoch   11/20 Batch 2/3 Cost: 6.099264\n",
            "Epoch   11/20 Batch 3/3 Cost: 4.173784\n",
            "Epoch   12/20 Batch 1/3 Cost: 2.654511\n",
            "Epoch   12/20 Batch 2/3 Cost: 6.453492\n",
            "Epoch   12/20 Batch 3/3 Cost: 15.150858\n",
            "Epoch   13/20 Batch 1/3 Cost: 4.653023\n",
            "Epoch   13/20 Batch 2/3 Cost: 15.436035\n",
            "Epoch   13/20 Batch 3/3 Cost: 2.557579\n",
            "Epoch   14/20 Batch 1/3 Cost: 0.782764\n",
            "Epoch   14/20 Batch 2/3 Cost: 11.099531\n",
            "Epoch   14/20 Batch 3/3 Cost: 9.068795\n",
            "Epoch   15/20 Batch 1/3 Cost: 6.403909\n",
            "Epoch   15/20 Batch 2/3 Cost: 6.137110\n",
            "Epoch   15/20 Batch 3/3 Cost: 13.660071\n",
            "Epoch   16/20 Batch 1/3 Cost: 8.099512\n",
            "Epoch   16/20 Batch 2/3 Cost: 8.175888\n",
            "Epoch   16/20 Batch 3/3 Cost: 7.408454\n",
            "Epoch   17/20 Batch 1/3 Cost: 4.129847\n",
            "Epoch   17/20 Batch 2/3 Cost: 9.192418\n",
            "Epoch   17/20 Batch 3/3 Cost: 5.929659\n",
            "Epoch   18/20 Batch 1/3 Cost: 2.362229\n",
            "Epoch   18/20 Batch 2/3 Cost: 6.821747\n",
            "Epoch   18/20 Batch 3/3 Cost: 15.261531\n",
            "Epoch   19/20 Batch 1/3 Cost: 4.151248\n",
            "Epoch   19/20 Batch 2/3 Cost: 9.162889\n",
            "Epoch   19/20 Batch 3/3 Cost: 5.968738\n",
            "Epoch   20/20 Batch 1/3 Cost: 6.335124\n",
            "Epoch   20/20 Batch 2/3 Cost: 8.115524\n",
            "Epoch   20/20 Batch 3/3 Cost: 2.521833\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "for epoch in range(num_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    x_train, y_train = samples\n",
        "    pred = model(x_train)\n",
        "\n",
        "    cost = F.mse_loss(pred, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, num_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
